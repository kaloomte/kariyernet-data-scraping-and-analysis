{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # HTML data structure\n",
    "from urllib.request import urlopen # Web client\n",
    "import re #Regular expression operations\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is our main page\n",
    "#in this project we web scrap job positions and more details about it\n",
    "\n",
    "my_url = 'https://www.kariyer.net/pozisyonlar' #this is our main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens the connection and downloads html page from url\n",
    "# parses html into a soup data structure to traverse html\n",
    "# as if it were a json data type.\n",
    "def getSoup(my_url):\n",
    "    uClient = urlopen(my_url) \n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    soup = BeautifulSoup(page_html, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first of we need more details statistics about positions\n",
    "#we need all pages for each position so we need get links from our main page\n",
    "links = []\n",
    "soup = getSoup(my_url)\n",
    "#in HTML, links are value of 'href' key\n",
    "for link in soup.findAll('a', attrs={'href': re.compile(\"\")}):\n",
    "    links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are unnecessary link\n",
    "del links[:42]\n",
    "del links[-36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display first five links\n",
    "links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding head of URL for searching\n",
    "add_site = 'https://www.kariyer.net'\n",
    "new_links = [add_site + j for j in links]\n",
    "new_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new list for searching total_participants, male and female distribution\n",
    "all_statics_add = '/nasil+olunur'\n",
    "all_statics_add_links = [n + all_statics_add for n in new_links]\n",
    "all_statics_add_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new list for searching job advertisements data\n",
    "href_text_link = []\n",
    "is_ilanlari = '/is-ilanlari'\n",
    "pozisyonlar = '/pozisyonlar'\n",
    "for k in new_links:\n",
    "    is_ilanlari_new_links = k.replace(pozisyonlar, is_ilanlari)\n",
    "    href_text_link.append(is_ilanlari_new_links)\n",
    "href_text_link[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a csv file for job advertisement number for each profession\n",
    "job_filename = 'jobs.csv'\n",
    "headers = 'job_adv.'\n",
    "f = open(job_filename, 'w')\n",
    "f.write(headers)\n",
    "#taken job advertisement number for each link via loop\n",
    "for jobadv in href_text_link:\n",
    "    page_soup = getSoup(jobadv)\n",
    "    #try to get number\n",
    "    try:\n",
    "        job_advertisement = page_soup.find_all('span',{'id':'totalJobCount'})[0].text\n",
    "        print('job_advertisement:' + job_advertisement)\n",
    "        f.write(job_advertisement + '\\n')\n",
    "    #there are missing number\n",
    "    except:\n",
    "        print('job_advertisement:' + '-')\n",
    "        f.write('-' + '\\n')\n",
    "    print('------------------------------------')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a csv file for job advertisement number for each profession\n",
    "filename = 'genderdistr.csv'\n",
    "headers = 'total_participants, male, female \\n' \n",
    "f = open(filename, 'w')\n",
    "f.write(headers)\n",
    "\n",
    "#taken job advertisement number for each link via loop\n",
    "for eachjob in all_statics_add_links:\n",
    "    page_soup = getSoup(eachjob)\n",
    "    #get datas\n",
    "    try:\n",
    "        female_distri = page_soup.findAll('div',{'class':'pg-chart-label female'})[0].text.split('\\n')[1].replace('%', '').replace(',','.')\n",
    "        male_distri = page_soup.findAll('div',{'class':'pg-chart-label male'})[0].text.split('\\n')[1].replace('%', '').replace(',', '.')\n",
    "        total_participants = page_soup.findAll('div', {'class':'pg-chart-main-text'})[0].text.split(\" \")[0]\n",
    "        print('total:' + total_participants)\n",
    "        print('female:' + female_distri)\n",
    "        print('male:' + male_distri)\n",
    "        f.write(total_participants + ', ' + male_distri + ', ' + female_distri + '\\n')\n",
    "    #for missing values\n",
    "    except:\n",
    "        f.write('-' + ', ' + '-' + ', ' + '-' + '\\n')\n",
    "        print('total:' + '-')\n",
    "        print('female:'+ '-')\n",
    "        print('male:' + '-')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_filename = 'maindata.csv'\n",
    "headers = 'job_name, mean_salary, max_salary, min_salary, first_grad, second_grad, third_grad, fourth_grad, fiveth_grad, first_department, second_department, third_department, fourth_department, fiveth_department, first_school, second_school, third_school, fourth_school, fiveth_school, first_skill, second_skill, third_skill, fourth_skill, fiveth_skill, number_of_entries \\n'\n",
    "f = open(job_filename, 'w')\n",
    "f.write(headers)\n",
    "\n",
    "for eachposition in new_links:\n",
    "    page_soup = getSoup(eachposition)\n",
    "    try:\n",
    "        job_name = page_soup.findAll('div', {'class':'pg-breadcrumb'})[0].findAll('a')[2].text\n",
    "        print('job_name:' + job_name)\n",
    "        f.write(job_name + ', ')   \n",
    "    except:\n",
    "        print('job_name:' + '-')\n",
    "        f.write('-' + ', ')\n",
    "    try:\n",
    "        mean_salary_value = page_soup.findAll('div', {'class':'pg-salary-box-value'})[0].text\n",
    "        max_salary_value = page_soup.findAll('div', {'class':'pg-salary-box-value'})[1].text\n",
    "        min_salary_value = page_soup.findAll('div', {'class':'pg-salary-box-value'})[2].text\n",
    "        print('mean_salary_value:' + mean_salary_value)\n",
    "        print('max_salary_value:' + max_salary_value)\n",
    "        print('min_salary_value:' + min_salary_value)\n",
    "        f.write(mean_salary_value + ', ' + max_salary_value + ', ' + min_salary_value + ',')\n",
    "    except:\n",
    "        print('mean_salary_value:' +'-')\n",
    "        print('max_salary_value:' + '-')\n",
    "        print('min_salary_value:' + '-')\n",
    "        f.write('-' + ', '+ '-' + ', ' + '-' + ', ')\n",
    "    try:\n",
    "        first_grad_ = page_soup.findAll('span', {'class':'pg-progress-left'})[0].text.replace(',', ' -')\n",
    "        second_grad_ = page_soup.findAll('span', {'class':'pg-progress-left'})[1].text.replace(',', ' -')\n",
    "        third_grad_ = page_soup.findAll('span', {'class':'pg-progress-left'})[2].text.replace(',', ' -')\n",
    "        fourth_grad_ = page_soup.findAll('span', {'class':'pg-progress-left'})[3].text.replace(',', ' -')\n",
    "        fiveth_grad_ = page_soup.findAll('span', {'class':'pg-progress-left'})[4].text.replace(',', ' -')\n",
    "        print('first_grad_ ' + first_grad_)\n",
    "        print('second_grad_ ' + second_grad_)\n",
    "        print('third_grad_' + third_grad_)\n",
    "        print('fourth_grad_' + fourth_grad_)\n",
    "        print('fiveth_grad_' + fiveth_grad_)\n",
    "        f.write(first_grad_ + ', ' + second_grad_ + ', ' + third_grad_ + ', ' + fourth_grad_ + ', ' + fiveth_grad_  + ', ')\n",
    "    except:\n",
    "        print('first_grad_:' + '-')\n",
    "        print('second_grad_:' + '-')\n",
    "        print('third_grad_:' + '-')\n",
    "        print('fourth_grad_:' + '-')\n",
    "        print('fiveth_grad_:' + '-')\n",
    "        f.write('-' + ', ' + '-' + ', ' + '-' + ', ' + '-' + ', ' + '-' + ', ')\n",
    "    try:\n",
    "        first_department = page_soup.findAll('span', {'class':'pg-progress-left'})[5].text\n",
    "        second_department = page_soup.findAll('span', {'class':'pg-progress-left'})[6].text\n",
    "        third_department = page_soup.findAll('span', {'class':'pg-progress-left'})[7].text\n",
    "        fourth_department = page_soup.findAll('span', {'class':'pg-progress-left'})[8].text\n",
    "        fiveth_department = page_soup.findAll('span', {'class':'pg-progress-left'})[9].text\n",
    "        print('first_departmant :'+ first_department)\n",
    "        print('second_departmant :'+ second_department)\n",
    "        print('third_departmant :' +third_department)\n",
    "        print('fourth_departmant :' +fourth_department)\n",
    "        print('fiveth_departmant :' +fiveth_department)\n",
    "        f.write(first_department + ', ' + second_department + ', ' + third_department + ', ' + fourth_department + ', ' + fiveth_department + ', ')\n",
    "    except:\n",
    "        print('first_departmant :' '-')\n",
    "        print('second_departmant :' '-')\n",
    "        print('third_departmant :' '-')\n",
    "        print('fourth_departmant :' '-')\n",
    "        print('fiveth_departmant :' '-')\n",
    "        f.write('-' + ', ' + '-' + ', ' + '-' + ', ' + '-' + ', ' + '-' + ', ')\n",
    "    try:\n",
    "        first_school = page_soup.findAll('ol', {'class':'pg-uni-list'})[0].findAll('span')[0].text\n",
    "        second_school = page_soup.findAll('ol', {'class':'pg-uni-list'})[0].findAll('span')[1].text\n",
    "        third_school = page_soup.findAll('ol', {'class':'pg-uni-list'})[0].findAll('span')[2].text\n",
    "        fourth_school = page_soup.findAll('ol', {'class':'pg-uni-list'})[0].findAll('span')[3].text\n",
    "        fiveth_school = page_soup.findAll('ol', {'class':'pg-uni-list'})[0].findAll('span')[4].text\n",
    "        print('first_school:' + first_school)\n",
    "        print('second_school:' + second_school)\n",
    "        print('third_school:' + third_school)\n",
    "        print('fourth_school:' + fourth_school)\n",
    "        print('fiveth_school:' + fiveth_school)\n",
    "        f.write(first_school + ', ' + second_school + ', ' +  third_school + ', ' + fourth_school + ', ' + fiveth_school+ ', ' )\n",
    "    except:\n",
    "        print('first_school:' + '-')\n",
    "        print('second_school:' + '-')\n",
    "        print('third_school:' + '-')\n",
    "        print('fourth_school:' + '-')\n",
    "        print('fiveth_school:' + '-')\n",
    "        f.write('-' + ', ' + '-' + ', ' + '-' + ', ' + '-' + ', ' + '-' + ', ')\n",
    "    try:\n",
    "        first_skill = page_soup.findAll('div', {'class':'pg-how-to-be-desc'})[0].findAll('span')[0].text\n",
    "        print('first_skill:' + first_skill)\n",
    "        f.write(first_skill + ',')\n",
    "    except:\n",
    "        print('first_skill:' + '-')\n",
    "        f.write('-' + ', ')\n",
    "    try:\n",
    "        second_skill = page_soup.findAll('div', {'class':'pg-how-to-be-desc'})[0].findAll('span')[1].text\n",
    "        print('second_skill :' + second_skill )\n",
    "        f.write(second_skill  + ',')\n",
    "    except:\n",
    "        print('second_skill :' + '-')\n",
    "        f.write('-' + ', ')\n",
    "    try:\n",
    "        third_skill = page_soup.findAll('div', {'class':'pg-how-to-be-desc'})[0].findAll('span')[2].text\n",
    "        print('third_skill:' + third_skill)\n",
    "        f.write(third_skill + ',')\n",
    "    except:\n",
    "        print('third_skill:' + '-')\n",
    "        f.write('-' + ', ')\n",
    "    try:\n",
    "        fourth_skill = page_soup.findAll('div', {'class':'pg-how-to-be-desc'})[0].findAll('span')[3].text\n",
    "        print('fourth_skill:' + fourth_skill)\n",
    "        f.write(fourth_skill + ',')\n",
    "    except:\n",
    "        print('fourth_skill:' + '-')\n",
    "        f.write('-' + ', ')\n",
    "    try:\n",
    "        fiveth_skill = page_soup.findAll('div', {'class':'pg-how-to-be-desc'})[0].findAll('span')[4].text\n",
    "        print('fiveth_skill:' + fiveth_skill)\n",
    "        f.write(fiveth_skill + ',')\n",
    "    except:\n",
    "        print('fiveth_skill:' + '-')\n",
    "        f.write('-' + ', ')\n",
    "    try:\n",
    "        number_of_entries = page_soup.findAll('div', {'class':'pg-salary-desc'})[0].findAll('strong')[0].text\n",
    "        print('number_of_entries:' + number_of_entries)\n",
    "        f.write(number_of_entries + ',' + '\\n')\n",
    "    except:\n",
    "        print('number_of_entries:' + '-')\n",
    "        f.write('-' + ',' + '\\n')\n",
    "    print('--------------------------------------------------------')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('maindata.txt', header=None, sep='\\n')\n",
    "df = df[0].str.split(',', expand=True)\n",
    "df.drop(df.iloc[:,-6:], axis=1, inplace=True)\n",
    "df.columns = df.iloc[0]\n",
    "df.drop(0,inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('jobs.txt').astype('str')\n",
    "df2['job_adv.'].replace('37.204', '0', inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read gender distribution file\n",
    "df3 = pd.read_csv('genderdistr.csv')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat all dataframe and sent into one general dataset csv file\n",
    "general_dataset = pd.concat([df, df2, df3], axis=1)\n",
    "general_dataset.to_csv('general_dataset.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>Employer Interest Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Galatasaray Üniversitesi</td>\n",
       "      <td>88,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sabancı Üniversitesi</td>\n",
       "      <td>86,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koç Üniversitesi</td>\n",
       "      <td>80,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boğaziçi Üniversitesi</td>\n",
       "      <td>79,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>İstanbul Teknik Üniversitesi (İTÜ)</td>\n",
       "      <td>76,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Adıyaman Üniversitesi</td>\n",
       "      <td>18,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Ankara Sosyal Bilimler Üniversitesi</td>\n",
       "      <td>18,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Ağrı İbrahim Çeçen Üniversitesi</td>\n",
       "      <td>17,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Sağlık Bilimleri Üniversitesi</td>\n",
       "      <td>16,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>İzmir Bakırçay Üniversitesi</td>\n",
       "      <td>14,6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              University Employer Interest Index\n",
       "0               Galatasaray Üniversitesi                    88,3\n",
       "1                   Sabancı Üniversitesi                    86,5\n",
       "2                       Koç Üniversitesi                    80,7\n",
       "3                  Boğaziçi Üniversitesi                    79,8\n",
       "4     İstanbul Teknik Üniversitesi (İTÜ)                    76,9\n",
       "..                                   ...                     ...\n",
       "169                Adıyaman Üniversitesi                    18,9\n",
       "170  Ankara Sosyal Bilimler Üniversitesi                    18,7\n",
       "171      Ağrı İbrahim Çeçen Üniversitesi                    17,9\n",
       "172        Sağlık Bilimleri Üniversitesi                    16,2\n",
       "173          İzmir Bakırçay Üniversitesi                    14,6\n",
       "\n",
       "[174 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get datas from website with getSoup function\n",
    "uni_url = 'https://www.kariyer.net/en-iyi-universiteler/universiteler'\n",
    "uni_soup = getSoup(uni_url)\n",
    "\n",
    "uni = uni_soup.findAll('div', {'class':'title-cell k-text singleLine t-2 col-6'})\n",
    "uni = [eachuni.get_text().strip() for eachuni in uni]\n",
    "\n",
    "perc = uni_soup.findAll('div', {'class':'title-cell t-2 pl-md-0 pl-sm-2 pl-xl-1 col-sm-3 col-md-2 col-4'})\n",
    "perc = [eachperc.get_text().strip() for eachperc in perc]\n",
    "\n",
    "\n",
    "d = {'University':uni, 'Employer Interest Index' : perc}\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>Employer Interest Index (for Department)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>İşletme Mühendisliği</td>\n",
       "      <td>86,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matematik Mühendisliği</td>\n",
       "      <td>83,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>İşletme (Almanca)</td>\n",
       "      <td>74,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>İşletme Enformatiği</td>\n",
       "      <td>64,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ekonomi - Yönetim Bilimleri Programları</td>\n",
       "      <td>64,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Tarih Öğretmenliği</td>\n",
       "      <td>18,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>İslami İlimler</td>\n",
       "      <td>18,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Türkçe Öğretmenliği</td>\n",
       "      <td>17,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Sosyal Bilgiler Öğretmenliği</td>\n",
       "      <td>17,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Kürt Dili Ve Edabiyatı</td>\n",
       "      <td>9,4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Department  \\\n",
       "0                       İşletme Mühendisliği   \n",
       "1                     Matematik Mühendisliği   \n",
       "2                          İşletme (Almanca)   \n",
       "3                        İşletme Enformatiği   \n",
       "4    Ekonomi - Yönetim Bilimleri Programları   \n",
       "..                                       ...   \n",
       "286                       Tarih Öğretmenliği   \n",
       "287                           İslami İlimler   \n",
       "288                      Türkçe Öğretmenliği   \n",
       "289             Sosyal Bilgiler Öğretmenliği   \n",
       "290                   Kürt Dili Ve Edabiyatı   \n",
       "\n",
       "    Employer Interest Index (for Department)  \n",
       "0                                       86,8  \n",
       "1                                       83,9  \n",
       "2                                       74,3  \n",
       "3                                       64,9  \n",
       "4                                       64,5  \n",
       "..                                       ...  \n",
       "286                                     18,1  \n",
       "287                                     18,0  \n",
       "288                                     17,1  \n",
       "289                                     17,1  \n",
       "290                                      9,4  \n",
       "\n",
       "[291 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get datas from website with getSoup function\n",
    "dep_url = 'https://www.kariyer.net/en-iyi-universiteler/bolumler'\n",
    "dep_soup = getSoup(dep_url)\n",
    "\n",
    "dep = dep_soup.findAll('div', {'class':'title-cell k-text singleLine t-2 col-6'})\n",
    "dep = [eachDep.get_text().strip() for eachDep in dep]\n",
    "\n",
    "perc1 = dep_soup.findAll('div', {'class':'title-cell t-2 pl-md-0 pl-sm-2 pl-xl-1 col-sm-3 col-md-2 col-4'})\n",
    "perc1 = [eachPerc.get_text().strip() for eachPerc in perc1]\n",
    "\n",
    "#There two list, concat them and make dataframe\n",
    "d1 = {'Department':dep, 'Employer Interest Index (for Department)' : perc1}\n",
    "df2 = pd.DataFrame(d1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employer Interest Index'] = df['Employer Interest Index'].apply(lambda x: float(x.replace('\"', '').replace(',','.')))\n",
    "df2['Employer Interest Index (for Department)'] = df2['Employer Interest Index (for Department)'].apply(lambda x: float(x.replace('\"', '').replace(',','.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('university_interest_index.csv', encoding='utf-8-sig', index=False)\n",
    "df2.to_csv('department_interest_index.csv', encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
